{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "645f2d39-69df-4c70-b238-9c21ebf35bc3",
   "metadata": {},
   "source": [
    "## Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4b1c7776-3136-42c1-b2c2-28720df05ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, pathlib\n",
    "shutil.rmtree(pathlib.Path.home()/\".cache\"/\"torch_extensions\", ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22415872-ee8d-40a0-8119-0c98f190ea3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patched: /users/project1/pt01183/Building-height-width/external/neurvps/neurvps/models/cpp/deform_conv.cpp\n",
      "Patched: /users/project1/pt01183/Building-height-width/external/neurvps/neurvps/models/cpp/deform_conv_cuda.cu\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "NEUR = Path(\"/users/project1/pt01183/Building-height-width/external/neurvps\")\n",
    "\n",
    "targets = [\n",
    "    NEUR/\"neurvps/models/cpp/deform_conv.cpp\",\n",
    "    NEUR/\"neurvps/models/cpp/deform_conv_cuda.cu\",\n",
    "]\n",
    "\n",
    "def patch_text(s: str) -> str:\n",
    "    t = s\n",
    "    # Deprecated .type() API → modern API\n",
    "    t = t.replace(\".type().is_cuda()\", \".is_cuda()\")\n",
    "    t = t.replace(\".type().scalarType()\", \".scalar_type()\")\n",
    "    # AT_DISPATCH...(... .type(), ...) → (... .scalar_type(), ...)\n",
    "    t = re.sub(r\"AT_DISPATCH_FLOATING_TYPES_AND_HALF\\(\\s*([A-Za-z0-9_]+)\\.type\\(\\)\",\n",
    "               r\"AT_DISPATCH_FLOATING_TYPES_AND_HALF(\\1.scalar_type()\", t)\n",
    "    t = re.sub(r\"AT_DISPATCH_FLOATING_TYPES\\(\\s*([A-Za-z0-9_]+)\\.type\\(\\)\",\n",
    "               r\"AT_DISPATCH_FLOATING_TYPES(\\1.scalar_type()\", t)\n",
    "    return t\n",
    "\n",
    "for p in targets:\n",
    "    src = p.read_text()\n",
    "    new = patch_text(src)\n",
    "    if new != src:\n",
    "        p.write_text(new)\n",
    "        print(\"Patched:\", p)\n",
    "    else:\n",
    "        print(\"No changes needed:\", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "64d2f840-34a4-45a0-a803-4ea395e56680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.13 | packaged by conda-forge | (main, Oct 26 2023, 18:07:37) [GCC 12.3.0]\n",
      "Mon Oct 13 16:53:37 2025       \n",
      "Torch: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA runtime (torch): 12.4\n",
      "GPU: NVIDIA A100 80GB PCIe\n",
      "Tensor device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# GPU + Torch sanity\n",
    "import sys, subprocess, os\n",
    "print(\"Python:\", sys.version)\n",
    "\n",
    "# show GPU/driver\n",
    "try:\n",
    "    out = subprocess.check_output([\"nvidia-smi\"], text=True)\n",
    "    print(out.splitlines()[0])\n",
    "except Exception as e:\n",
    "    print(\"nvidia-smi not available:\", e)\n",
    "\n",
    "# torch check\n",
    "try:\n",
    "    import torch\n",
    "    print(\"Torch:\", torch.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA runtime (torch):\", torch.version.cuda)\n",
    "        print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "        x = torch.rand(2,2).cuda()\n",
    "        print(\"Tensor device:\", x.device)\n",
    "except Exception as e:\n",
    "    print(\"Torch not installed or failed to import:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2cf81-a086-4084-9bab-71dd8e85dfc0",
   "metadata": {},
   "source": [
    "## Make a GSV-specific config (sets the correct focal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc06d3b-0e82-4702-b88a-845c30890157",
   "metadata": {},
   "source": [
    "Use this first. It tells NeurVPS the focal that matches your 640×640, FOV = 100° images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c924f967-9281-4ea5-8f82-7d4611135587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /users/project1/pt01183/Building-height-width/external/neurvps/logs/tmm17/config_gsv.yaml\n",
      "focal(px): 268.51188197672957\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml, math\n",
    "\n",
    "REPO   = Path(\"/users/project1/pt01183/Building-height-width\")\n",
    "NEUR   = REPO / \"external\" / \"neurvps\"\n",
    "BASE   = NEUR / \"logs\" / \"tmm17\" / \"config.yaml\"        # downloaded from HF\n",
    "CFG_GSV= NEUR / \"logs\" / \"tmm17\" / \"config_gsv.yaml\"\n",
    "\n",
    "# your GSV camera numbers (from earlier): fov=100°, width=640\n",
    "fov_deg = 100.0\n",
    "W = 640\n",
    "f_px = (W/2.0) / math.tan(math.radians(fov_deg/2.0))   # ≈ 268.51 px\n",
    "\n",
    "with open(BASE, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# Ensure expected structure exists\n",
    "cfg.setdefault(\"data\", {})\n",
    "cfg[\"data\"][\"focal\"] = float(f_px)\n",
    "\n",
    "# IMPORTANT: the TMM17 checkpoint expects NO conic/DCN branch:\n",
    "cfg.setdefault(\"model\", {})\n",
    "cfg[\"model\"][\"conic_6x\"] = False   # <- critical\n",
    "# (leave the rest of model settings as-is; do not add new keys)\n",
    "\n",
    "with open(CFG_GSV, \"w\") as f:\n",
    "    yaml.safe_dump(cfg, f, sort_keys=False)\n",
    "\n",
    "print(\"Wrote:\", CFG_GSV)\n",
    "print(\"focal(px):\", f_px)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34089ba6-781a-41d4-a496-3d966901d69a",
   "metadata": {},
   "source": [
    "## Gather your 5 RGBs (already 640×640) into a small input folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41efd8f-27d0-4de7-8493-3474fdbbf13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 5 images to /users/project1/pt01183/Building-height-width/external/neurvps/data/my5_sq:\n",
      " - 6_196.jpg\n",
      " - 2_190.jpg\n",
      " - 7_4.jpg\n",
      " - 8_139.jpg\n",
      " - 9_196.jpg\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil, glob\n",
    "\n",
    "REPO = Path(\"/users/project1/pt01183/Building-height-width\")\n",
    "NEURVPS = REPO / \"external\" / \"neurvps\"\n",
    "\n",
    "# <-- your actual RGB source folder\n",
    "RAW_DIR = REPO / \"Gdańsk, Poland\" / \"save_rgb\" / \"imgs\"\n",
    "\n",
    "KEEP_IDS = [\"6_196\",\"2_190\",\"7_4\",\"8_139\",\"9_196\"]\n",
    "\n",
    "# We'll just copy to a small working folder for NeurVPS (no resize needed)\n",
    "SQ_DIR  = NEURVPS / \"data\" / \"my5_sq\"\n",
    "SQ_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def copy_by_id(src_dir: Path, sid: str, dst_dir: Path) -> Path | None:\n",
    "    # try common extensions; if filenames have suffixes, also try glob with sid.*\n",
    "    candidates = []\n",
    "    for ext in (\".jpg\",\".jpeg\",\".png\",\".JPG\",\".PNG\"):\n",
    "        p = src_dir / f\"{sid}{ext}\"\n",
    "        if p.exists():\n",
    "            candidates.append(p)\n",
    "    if not candidates:\n",
    "        # fallback: any file that starts with id (e.g., sid_*.jpg)\n",
    "        candidates = [Path(p) for p in glob.glob(str(src_dir / f\"{sid}.*\"))]\n",
    "    if not candidates:\n",
    "        return None\n",
    "    src = sorted(candidates, key=lambda x: x.suffix.lower())[0]\n",
    "    dst = dst_dir / (sid + src.suffix.lower())\n",
    "    shutil.copy2(src, dst)\n",
    "    return dst\n",
    "\n",
    "copied = []\n",
    "for sid in KEEP_IDS:\n",
    "    outp = copy_by_id(RAW_DIR, sid, SQ_DIR)\n",
    "    if outp:\n",
    "        copied.append(outp.name)\n",
    "    else:\n",
    "        print(f\"[WARN] Could not find an image for ID {sid} in {RAW_DIR}\")\n",
    "\n",
    "print(f\"Copied {len(copied)} images to {SQ_DIR}:\")\n",
    "for name in copied:\n",
    "    print(\" -\", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399bdbcc-b764-4fab-ac0e-57d9cbd5bf57",
   "metadata": {},
   "source": [
    "## Create the runner script (one-time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f96284-ca67-4349-b987-e5759b7b4efd",
   "metadata": {},
   "source": [
    "This is a small helper we write ourselves so you can run a folder and get per-image JSONs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "110eb6ef-fb0e-43bb-9668-a1736c803650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runner updated: /users/project1/pt01183/Building-height-width/external/neurvps/misc/run_on_folder.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "NEURVPS_ROOT = Path(\"/users/project1/pt01183/Building-height-width/external/neurvps\")\n",
    "runner_path = NEURVPS_ROOT / \"misc\" / \"run_on_folder.py\"\n",
    "runner_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "runner_code = r'''\n",
    "import os, sys, glob, json, torch, yaml, importlib, re\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "def model_wants_anet_prefix(model) -> bool:\n",
    "    mk = list(model.state_dict().keys())\n",
    "    return any(k.startswith(\"anet.\") for k in mk)\n",
    "\n",
    "def remap_state_for_model(state: dict, model_keys: list[str]) -> dict:\n",
    "    \"\"\"\n",
    "    Map checkpoint keys to match the model's naming.\n",
    "    Handles cases where the model uses:\n",
    "      - top-level 'backbone.*' and 'anet.fc*/bn*/conv*/score*' heads\n",
    "      - or all 'anet.*'\n",
    "    \"\"\"\n",
    "    mk = model_keys\n",
    "    has_anet_any          = any(k.startswith(\"anet.\") for k in mk)\n",
    "    has_anet_backbone     = any(k.startswith(\"anet.backbone.\") for k in mk)\n",
    "    has_top_backbone      = any(k.startswith(\"backbone.\") for k in mk)\n",
    "\n",
    "    out = {}\n",
    "    for k, v in state.items():\n",
    "        kk = k\n",
    "\n",
    "        # Normalize common wrappers first\n",
    "        for pref in (\"module.\", \"model.\"):\n",
    "            if kk.startswith(pref):\n",
    "                kk = kk[len(pref):]\n",
    "\n",
    "        # If model has top-level backbone.* (not anet.backbone.*), collapse anet.backbone.* -> backbone.*\n",
    "        if has_top_backbone and not has_anet_backbone and kk.startswith(\"anet.backbone.\"):\n",
    "            kk = kk[len(\"anet.\"):]  # -> backbone.*\n",
    "\n",
    "        # If model expects anet.* but ckpt lacks it on head blocks/backbone, add it\n",
    "        if has_anet_any and not kk.startswith(\"anet.\"):\n",
    "            if kk.startswith(\"backbone.\") or re.match(r\"^(fc[0-3]|bn[1-4]|conv[1-4]|score)(\\.|$)\", kk):\n",
    "                kk = \"anet.\" + kk\n",
    "\n",
    "        # If model does NOT expect anet.*, strip it\n",
    "        if not has_anet_any and kk.startswith(\"anet.\"):\n",
    "            kk = kk[len(\"anet.\"):]\n",
    "\n",
    "        out[kk] = v\n",
    "    return out\n",
    "\n",
    "    \n",
    "# Ensure NeurVPS repo root is on sys.path\n",
    "HERE = os.path.dirname(__file__)\n",
    "ROOT = os.path.dirname(os.path.dirname(HERE))   # .../external/neurvps\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.insert(0, ROOT)\n",
    "\n",
    "# Import global config singleton M\n",
    "cfgmod = importlib.import_module('neurvps.config')  # has M\n",
    "from neurvps.models.vanishing_net import VanishingNet\n",
    "\n",
    "def to_pixel_local(v, focal, width, height=None):\n",
    "    vx, vy, vz = float(v[0]), float(v[1]), float(v[2])\n",
    "    W = float(width)\n",
    "    H = float(height if height is not None else width)\n",
    "    cx, cy = W/2.0, H/2.0\n",
    "    eps = 1e-6\n",
    "    if -eps < vz < eps:\n",
    "        vz = eps if vz >= 0 else -eps\n",
    "    x = focal * vx / vz + cx\n",
    "    y = focal * vy / vz + cy\n",
    "    return np.array([x, y], dtype=np.float32)\n",
    "\n",
    "def apply_model_cfg_to_M(model_cfg: dict):\n",
    "    for k, v in (model_cfg or {}).items():\n",
    "        try:\n",
    "            setattr(cfgmod.M, k, v)\n",
    "        except Exception:\n",
    "            try:\n",
    "                cfgmod.M[k] = v  # type: ignore\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "def load_model(cfg_path, ckpt_path, device):\n",
    "    with open(cfg_path, \"r\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "\n",
    "    model_cfg = (cfg.get(\"model\") or {})\n",
    "    model_cfg.setdefault(\"conic_6x\", False)\n",
    "    model_cfg.setdefault(\"upsample_scale\", 1)\n",
    "    model_cfg.setdefault(\"output_stride\", 4)\n",
    "    apply_model_cfg_to_M(model_cfg)\n",
    "\n",
    "    model = VanishingNet(model_cfg).to(device).eval()\n",
    "\n",
    "    raw = torch.load(ckpt_path, map_location=device)\n",
    "    mk = list(model.state_dict().keys())\n",
    "    state = remap_state_for_model(state, mk)\n",
    "\n",
    "    incompatible = model.load_state_dict(state, strict=False)\n",
    "    try:\n",
    "        miss = list(incompatible.missing_keys)\n",
    "        unexp = list(incompatible.unexpected_keys)\n",
    "    except Exception:\n",
    "        miss, unexp = [], []\n",
    "    print(f\"[state_dict] loaded with missing={len(miss)} unexpected={len(unexp)}\")\n",
    "    if unexp[:8]: print(\"  unexpected (first 8):\", unexp[:8])\n",
    "    if miss[:8]:  print(\"  missing    (first 8):\", miss[:8])\n",
    "\n",
    "    focal = float(cfg.get(\"data\", {}).get(\"focal\", 1.0))\n",
    "    return model, focal\n",
    "\n",
    "def infer_one(model, device, img_path):\n",
    "    img = io.imread(img_path)\n",
    "    if img.ndim == 2:\n",
    "        img = np.stack([img]*3, axis=-1)\n",
    "    H, W = img.shape[:2]\n",
    "    x = torch.from_numpy(img).permute(2,0,1).float()/255.0\n",
    "    x = x.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)  # dict with unit vectors: vp_x, vp_y, vp_z\n",
    "    out = {}\n",
    "    for k in (\"vp_x\",\"vp_y\",\"vp_z\"):\n",
    "        if k in pred:\n",
    "            v = pred[k][0].detach().cpu().numpy()\n",
    "            px = to_pixel_local(v, focal=focal, width=W, height=H)\n",
    "            out[k] = [float(px[0]), float(px[1])]\n",
    "    return out\n",
    "\n",
    "def main(in_dir, out_dir, cfg_path, ckpt_path, device=\"cuda:0\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    model, focal = load_model(cfg_path, ckpt_path, device)\n",
    "    imgs = sorted([p for p in glob.glob(os.path.join(in_dir, \"*\")) if os.path.isfile(p)])\n",
    "    print(f\"Found {len(imgs)} images in {in_dir}\")\n",
    "    for p in imgs:\n",
    "        vps = infer_one(model, focal, device, p)\n",
    "        base = os.path.splitext(os.path.basename(p))[0]\n",
    "        with open(os.path.join(out_dir, base + \".json\"), \"w\") as f:\n",
    "            json.dump(vps, f)\n",
    "        print(\"Wrote\", base + \".json\")\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    in_dir  = sys.argv[1]\n",
    "    out_dir = sys.argv[2]\n",
    "    cfg     = sys.argv[3]\n",
    "    ckpt    = sys.argv[4]\n",
    "    device  = sys.argv[5] if len(sys.argv) > 5 else \"cuda:0\"\n",
    "    main(in_dir, out_dir, cfg, ckpt, device)\n",
    "'''\n",
    "runner_path.write_text(runner_code)\n",
    "print(\"Runner updated:\", runner_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f67de-2e5a-4275-a937-178c08d3ba77",
   "metadata": {},
   "source": [
    "## Run NeurVPS on the folder and get JSON VPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b8e9220-168d-432f-9b6a-fad100f5538c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "All deps imported OK.\n"
     ]
    }
   ],
   "source": [
    "# Install NeurVPS runtime deps into the current kernel env\n",
    "%pip install --quiet tensorboardX pyyaml docopt matplotlib scikit-image opencv-python tqdm\n",
    "\n",
    "# Sanity check\n",
    "import tensorboardX, yaml, docopt, matplotlib, skimage, cv2, tqdm\n",
    "print(\"All deps imported OK.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fdbeca-09d3-4a3f-981d-6ea97c0d1d24",
   "metadata": {},
   "source": [
    "Convert the checkpoint to a pure state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12b08ecc-173d-4a3e-88b4-1d7b3c354659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples (old -> new):\n",
      "  backbone.conv1.weight  ->  anet.backbone.conv1.weight\n",
      "  backbone.conv1.bias  ->  anet.backbone.conv1.bias\n",
      "  backbone.bn1.weight  ->  anet.backbone.bn1.weight\n",
      "  backbone.bn1.bias  ->  anet.backbone.bn1.bias\n",
      "  backbone.bn1.running_mean  ->  anet.backbone.bn1.running_mean\n",
      "Wrote: /users/project1/pt01183/Building-height-width/external/neurvps/logs/tmm17/checkpoint_state_anetfix.pth num_keys: 413\n"
     ]
    }
   ],
   "source": [
    "import torch, re\n",
    "from pathlib import Path\n",
    "\n",
    "SRC = Path(\"/users/project1/pt01183/Building-height-width/external/neurvps/logs/tmm17/checkpoint_state_vps.pth\")\n",
    "DST = SRC.with_name(\"checkpoint_state_anetfix.pth\")\n",
    "\n",
    "sd = torch.load(SRC, map_location=\"cpu\")\n",
    "new_sd = {}\n",
    "\n",
    "for k, v in sd.items():\n",
    "    nk = k\n",
    "    # If backbone.* -> anet.backbone.*\n",
    "    if nk.startswith(\"backbone.\"):\n",
    "        nk = \"anet.\" + nk\n",
    "    # If it's one of the A-Net head blocks -> add anet.* in front\n",
    "    elif re.match(r\"^(fc[0-3]|bn[1-4]|conv[1-4])(\\.|$)\", nk):\n",
    "        nk = \"anet.\" + nk\n",
    "    # else: leave as-is\n",
    "    new_sd[nk] = v\n",
    "\n",
    "print(\"Examples (old -> new):\")\n",
    "for i, (ok, ov) in enumerate(sd.items()):\n",
    "    if i >= 5: break\n",
    "    nk = ok\n",
    "    if nk.startswith(\"backbone.\"):\n",
    "        nk = \"anet.\" + nk\n",
    "    elif re.match(r\"^(fc[0-3]|bn[1-4]|conv[1-4])(\\.|$)\", nk):\n",
    "        nk = \"anet.\" + nk\n",
    "    print(f\"  {ok}  ->  {nk}\")\n",
    "\n",
    "torch.save(new_sd, DST)\n",
    "print(\"Wrote:\", DST, \"num_keys:\", len(new_sd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "df4e53c5-3005-4119-a028-48fc90fe064e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has anet?: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "sd = torch.load(\"/users/project1/pt01183/Building-height-width/external/neurvps/logs/tmm17/checkpoint_state_anetfix.pth\", map_location=\"cpu\")\n",
    "print(\"has anet?:\", any(k.startswith(\"anet.\") for k in sd.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c32c8567-0be1-4850-abdc-aad4a864f2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running:\n",
      "  /mnt/host_scratch/envs/new_geospatial_env/bin/python /users/project1/pt01183/Building-height-width/external/neurvps/misc/run_on_folder.py /users/project1/pt01183/Building-height-width/external/neurvps/data/my5_sq /users/project1/pt01183/Building-height-width/external/neurvps/logs/tmm17/my5_vpts /users/project1/pt01183/Building-height-width/external/neurvps/logs/tmm17/config_gsv.yaml /users/project1/pt01183/Building-height-width/external/neurvps/logs/tmm17/checkpoint_state_anetfix.pth cuda:0\n",
      "[state_dict] loaded with missing=0 unexpected=377\n",
      "  unexpected (first 8): ['anet.backbone.conv1.weight', 'anet.backbone.conv1.bias', 'anet.backbone.bn1.weight', 'anet.backbone.bn1.bias', 'anet.backbone.bn1.running_mean', 'anet.backbone.bn1.running_var', 'anet.backbone.bn1.num_batches_tracked', 'anet.backbone.layer1.0.bn1.weight']\n",
      "Found 5 images in /users/project1/pt01183/Building-height-width/external/neurvps/data/my5_sq\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/project1/pt01183/Building-height-width/external/neurvps/misc/run_on_folder.py\", line 129, in <module>\n",
      "    main(in_dir, out_dir, cfg, ckpt, device)\n",
      "  File \"/users/project1/pt01183/Building-height-width/external/neurvps/misc/run_on_folder.py\", line 116, in main\n",
      "    vps = infer_one(model, focal, device, p)\n",
      "  File \"/users/project1/pt01183/Building-height-width/external/neurvps/misc/run_on_folder.py\", line 101, in infer_one\n",
      "    pred = model(x, focal=focal)  # dict with unit vectors: vp_x, vp_y, vp_z\n",
      "  File \"/mnt/host_scratch/envs/new_geospatial_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/mnt/host_scratch/envs/new_geospatial_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "TypeError: VanishingNet.forward() got an unexpected keyword argument 'focal'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, subprocess\n",
    "\n",
    "REPO = \"/users/project1/pt01183/Building-height-width\"\n",
    "NEUR = f\"{REPO}/external/neurvps\"\n",
    "\n",
    "in_dir  = f\"{NEUR}/data/my5_sq\"\n",
    "out_dir = f\"{NEUR}/logs/tmm17/my5_vpts\"\n",
    "cfg_gsv = f\"{NEUR}/logs/tmm17/config_gsv.yaml\"\n",
    "ckpt = f\"{NEUR}/logs/tmm17/checkpoint_state_anetfix.pth\" # <-- use cleaned file\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "env = os.environ.copy()\n",
    "env[\"PYTHONPATH\"] = NEUR\n",
    "env.pop(\"TORCH_CUDA_ARCH_LIST\", None)\n",
    "\n",
    "cmd = [\n",
    "    \"/mnt/host_scratch/envs/new_geospatial_env/bin/python\",\n",
    "    f\"{NEUR}/misc/run_on_folder.py\",\n",
    "    in_dir, out_dir, cfg_gsv, ckpt, \"cuda:0\"\n",
    "]\n",
    "print(\"Running:\\n \", \" \".join(cmd))\n",
    "res = subprocess.run(cmd, capture_output=True, text=True, env=env)\n",
    "print(res.stdout)\n",
    "print(res.stderr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c4f3e8-945c-4b03-a5a3-2a9f3f6aa4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
