{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caee12b6-c9c7-4375-a1f1-57e145001412",
   "metadata": {},
   "source": [
    "## Make a GSV-specific config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e92f36-5557-41e6-a923-26e4fbfd42be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml, math\n",
    "\n",
    "REPO   = Path(\"/users/project1/pt01183/Building-height-width\")\n",
    "NEUR   = REPO / \"external\" / \"neurvps\"\n",
    "BASE   = NEUR / \"logs\" / \"tmm17\" / \"config.yaml\"        # downloaded from HF\n",
    "CFG_GSV= NEUR / \"logs\" / \"tmm17\" / \"config_gsv.yaml\"\n",
    "\n",
    "# your GSV camera numbers (from earlier): fov=100°, width=640\n",
    "fov_deg = 100.0\n",
    "W = 640\n",
    "f_px = (W/2.0) / math.tan(math.radians(fov_deg/2.0))   # ≈ 268.51 px\n",
    "\n",
    "with open(BASE, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# Ensure expected structure exists\n",
    "cfg.setdefault(\"data\", {})\n",
    "cfg[\"data\"][\"focal\"] = float(f_px)\n",
    "\n",
    "# IMPORTANT: the TMM17 checkpoint expects NO conic/DCN branch:\n",
    "cfg.setdefault(\"model\", {})\n",
    "cfg[\"model\"][\"conic_6x\"] = False   # <- critical\n",
    "# (leave the rest of model settings as-is; do not add new keys)\n",
    "\n",
    "with open(CFG_GSV, \"w\") as f:\n",
    "    yaml.safe_dump(cfg, f, sort_keys=False)\n",
    "\n",
    "print(\"Wrote:\", CFG_GSV)\n",
    "print(\"focal(px):\", f_px)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9cd823-efd7-4a8d-8ab7-54c75a5ffba7",
   "metadata": {},
   "source": [
    "## Gather your 5 RGBs (already 640×640) into a small input folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443b0c4e-2cb0-41ce-aa13-cd09e55a6707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil, glob\n",
    "\n",
    "REPO = Path(\"/users/project1/pt01183/Building-height-width\")\n",
    "NEURVPS = REPO / \"external\" / \"neurvps\"\n",
    "\n",
    "# <-- your actual RGB source folder\n",
    "RAW_DIR = REPO / \"Gdańsk, Poland\" / \"save_rgb\" / \"imgs\"\n",
    "\n",
    "KEEP_IDS = [\"6_196\",\"2_190\",\"7_4\",\"8_139\",\"9_196\"]\n",
    "\n",
    "# We'll just copy to a small working folder for NeurVPS (no resize needed)\n",
    "SQ_DIR  = NEURVPS / \"data\" / \"my5_sq\"\n",
    "SQ_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def copy_by_id(src_dir: Path, sid: str, dst_dir: Path) -> Path | None:\n",
    "    # try common extensions; if filenames have suffixes, also try glob with sid.*\n",
    "    candidates = []\n",
    "    for ext in (\".jpg\",\".jpeg\",\".png\",\".JPG\",\".PNG\"):\n",
    "        p = src_dir / f\"{sid}{ext}\"\n",
    "        if p.exists():\n",
    "            candidates.append(p)\n",
    "    if not candidates:\n",
    "        # fallback: any file that starts with id (e.g., sid_*.jpg)\n",
    "        candidates = [Path(p) for p in glob.glob(str(src_dir / f\"{sid}.*\"))]\n",
    "    if not candidates:\n",
    "        return None\n",
    "    src = sorted(candidates, key=lambda x: x.suffix.lower())[0]\n",
    "    dst = dst_dir / (sid + src.suffix.lower())\n",
    "    shutil.copy2(src, dst)\n",
    "    return dst\n",
    "\n",
    "copied = []\n",
    "for sid in KEEP_IDS:\n",
    "    outp = copy_by_id(RAW_DIR, sid, SQ_DIR)\n",
    "    if outp:\n",
    "        copied.append(outp.name)\n",
    "    else:\n",
    "        print(f\"[WARN] Could not find an image for ID {sid} in {RAW_DIR}\")\n",
    "\n",
    "print(f\"Copied {len(copied)} images to {SQ_DIR}:\")\n",
    "for name in copied:\n",
    "    print(\" -\", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4d5da5-1a2c-4f8a-95c5-ad348d937a60",
   "metadata": {},
   "source": [
    "## Paths and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8650adfd-09b8-4e9b-ae7f-2dce46b94ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setup] added to sys.path: /users/project1/pt01183/Building-height-width/external/neurvps\n",
      "[setup] neurvps directory: /users/project1/pt01183/Building-height-width/external/neurvps\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys, os\n",
    "import importlib, types\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import math\n",
    "\n",
    "# 1. Ensure NeurVPS is on path FIRST\n",
    "REPO_ROOT = \"/users/project1/pt01183/Building-height-width\"\n",
    "NEURVPS_ROOT = Path(REPO_ROOT) / \"external\" / \"neurvps\"\n",
    "\n",
    "def ensure_neurvps_on_path(root: str):\n",
    "    root = os.path.abspath(root)\n",
    "    candidates = [root, os.path.join(root, \"src\")]\n",
    "    for c in candidates:\n",
    "        if os.path.isdir(os.path.join(c, \"neurvps\")):\n",
    "            if c not in sys.path:\n",
    "                sys.path.insert(0, c)\n",
    "            print(f\"[setup] added to sys.path: {c}\")\n",
    "            return c\n",
    "    raise RuntimeError(f\"neurvps not found under {root}\")\n",
    "\n",
    "sys_path = ensure_neurvps_on_path(str(NEURVPS_ROOT))\n",
    "print(f\"[setup] neurvps directory: {sys_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95de4a88-a263-4e4e-94e3-eb9c6d950ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Patch neurvps.config AFTER it's imported by model loading\n",
    "# We'll do this by creating a hook that patches it when needed\n",
    "\n",
    "def patch_neurvps_config():\n",
    "    \"\"\"Patch the C object in neurvps.config to add io.num_vpts\"\"\"\n",
    "    try:\n",
    "        # Import the config module\n",
    "        from neurvps.config import C, M\n",
    "        from neurvps.box import Box\n",
    "        \n",
    "        print(f\"[patch] C type: {type(C).__name__}\")\n",
    "        \n",
    "        # Check if C already has io.num_vpts\n",
    "        try:\n",
    "            val = C.io.num_vpts\n",
    "            print(f\"[patch] C.io.num_vpts already exists: {val}\")\n",
    "            return C, M\n",
    "        except (AttributeError, KeyError):\n",
    "            print(\"[patch] C.io.num_vpts not found, adding it\")\n",
    "        \n",
    "        # Add io.num_vpts to C\n",
    "        if isinstance(C, Box):\n",
    "            # Use Box methods\n",
    "            if \"io\" not in C:\n",
    "                C[\"io\"] = Box()\n",
    "            C[\"io\"][\"num_vpts\"] = 3\n",
    "        else:\n",
    "            # Use attribute access\n",
    "            if not hasattr(C, \"io\"):\n",
    "                C.io = Box() if isinstance(C, Box) else types.SimpleNamespace()\n",
    "            if hasattr(C.io, \"__setitem__\"):\n",
    "                C.io[\"num_vpts\"] = 3\n",
    "            else:\n",
    "                C.io.num_vpts = 3\n",
    "        \n",
    "        # Verify it worked\n",
    "        val = C.io.num_vpts\n",
    "        print(f\"[patch] Successfully set C.io.num_vpts = {val}\")\n",
    "        \n",
    "        return C, M\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[patch] Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cca5d767-aad6-4dff-a8da-0a4cac41d11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[config] focal=268.51px, conic_6x=False\n",
      "[config] saved to /users/project1/pt01183/Building-height-width/external/neurvps/logs/tmm17/config_gsv.yaml\n"
     ]
    }
   ],
   "source": [
    "# 3. CONFIGURATION\n",
    "BASE_CFG = NEURVPS_ROOT / \"logs\" / \"tmm17\" / \"config.yaml\"\n",
    "CFG_GSV = NEURVPS_ROOT / \"logs\" / \"tmm17\" / \"config_gsv.yaml\"\n",
    "CKPT = NEURVPS_ROOT / \"logs\" / \"tmm17\" / \"checkpoint_state_anet.pth\"\n",
    "\n",
    "# Camera intrinsics\n",
    "fov_deg = 100.0\n",
    "W = 640\n",
    "f_px = (W / 2.0) / math.tan(math.radians(fov_deg / 2.0))\n",
    "\n",
    "# Create config for GSV inference\n",
    "if BASE_CFG.exists():\n",
    "    with open(BASE_CFG, \"r\") as f:\n",
    "        cfg = yaml.safe_load(f) or {}\n",
    "else:\n",
    "    cfg = {}\n",
    "\n",
    "cfg.setdefault(\"data\", {})\n",
    "cfg[\"data\"][\"focal\"] = float(f_px)\n",
    "cfg.setdefault(\"model\", {})\n",
    "cfg[\"model\"][\"conic_6x\"] = False\n",
    "\n",
    "with open(CFG_GSV, \"w\") as f:\n",
    "    yaml.safe_dump(cfg, f, sort_keys=False)\n",
    "\n",
    "print(f\"[config] focal={f_px:.2f}px, conic_6x=False\")\n",
    "print(f\"[config] saved to {CFG_GSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4756009-e921-46f2-8731-940b30d55d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model] loading configuration and model...\n",
      "[model] successfully imported VanishingNet\n",
      "[model] patching neurvps.config...\n",
      "[patch] C type: Box\n",
      "[patch] C.io.num_vpts already exists: 3\n",
      "[patch] Wrapped neurvps.models.vanishing_net.orth/sample_sphere for shape safety\n",
      "[model] reading config from /users/project1/pt01183/Building-height-width/external/neurvps/logs/tmm17/config_gsv.yaml\n",
      "[model] output_stride=4, upsample_scale=1\n",
      "[model] using ResNet50 backbone\n",
      "[model] creating VanishingNet...\n",
      "[model] VanishingNet created successfully\n",
      "[model] loading checkpoint from /users/project1/pt01183/Building-height-width/external/neurvps/logs/tmm17/checkpoint_state_anet.pth\n",
      "[model] checkpoint loaded | type=dict\n",
      "[model] using checkpoint dict directly as state\n",
      "[model] state_dict has 413 keys\n",
      "[model] loaded | missing=215 unexpected=0\n",
      "✓ Model ready | focal=268.51px | device=cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 4. MODEL LOADING\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def _make_torchvision_backbone(which=\"resnet50\", pretrained=False, out_layer=\"layer3\"):\n",
    "    try:\n",
    "        from torchvision import models\n",
    "    except Exception:\n",
    "        return None\n",
    "    \n",
    "    if which == \"resnet50\":\n",
    "        m = models.resnet50(\n",
    "            weights=models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        )\n",
    "    elif which == \"resnet34\":\n",
    "        m = models.resnet34(\n",
    "            weights=models.ResNet34_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported backbone: {which}\")\n",
    "    \n",
    "    layers = [m.conv1, m.bn1, m.relu, m.maxpool, m.layer1, m.layer2, m.layer3]\n",
    "    if out_layer == \"layer4\":\n",
    "        layers.append(m.layer4)\n",
    "    \n",
    "    core = nn.Sequential(*layers)\n",
    "    \n",
    "    class Wrap(nn.Module):\n",
    "        def __init__(self, core):\n",
    "            super().__init__()\n",
    "            self.core = core\n",
    "        def forward(self, x):\n",
    "            return (self.core(x),)\n",
    "    \n",
    "    return Wrap(core)\n",
    "\n",
    "class TinyBackbone(nn.Module):\n",
    "    def __init__(self, in_ch=3, feat_ch=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 32, 3, stride=2, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, feat_ch, 3, stride=2, padding=1), nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return (self.net(x),)\n",
    "\n",
    "def load_model_robust(cfg_path: str, ckpt_path: str, device: str):\n",
    "    print(\"[model] loading configuration and model...\")\n",
    "    \n",
    "    # Import VanishingNet first\n",
    "    try:\n",
    "        from neurvps.models.vanishing_net import VanishingNet\n",
    "        print(\"[model] successfully imported VanishingNet\")\n",
    "    except ImportError as e:\n",
    "        print(f\"[model] ERROR: could not import VanishingNet: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # NOW patch the config after neurvps modules are imported\n",
    "    print(\"[model] patching neurvps.config...\")\n",
    "    cfg_C, cfg_M = patch_neurvps_config()\n",
    "\n",
    "    # 3) >>> INSERT THIS MONKEY-PATCH RIGHT HERE <<<\n",
    "    import numpy as _np\n",
    "    from neurvps.models import vanishing_net as _vn\n",
    "\n",
    "    if not hasattr(_vn, \"_safe_patched\"):\n",
    "        _orig_orth = _vn.orth\n",
    "        _orig_sample_sphere = _vn.sample_sphere\n",
    "\n",
    "        def _safe_orth(v):\n",
    "            v = _np.asarray(v, dtype=_np.float32).reshape(3)  # ensure shape (3,)\n",
    "            return _orig_orth(v)\n",
    "\n",
    "        def _safe_sample_sphere(v, st, ed):\n",
    "            v = _np.asarray(v, dtype=_np.float32).reshape(3)  # ensure shape (3,)\n",
    "            return _orig_sample_sphere(v, st, ed)\n",
    "\n",
    "        _vn.orth = _safe_orth\n",
    "        _vn.sample_sphere = _safe_sample_sphere\n",
    "        _vn._safe_patched = True\n",
    "        print(\"[patch] Wrapped neurvps.models.vanishing_net.orth/sample_sphere for shape safety\")\n",
    "    # 3) >>> END INSERT <<<\n",
    "    \n",
    "    # Load config from YAML\n",
    "    print(f\"[model] reading config from {cfg_path}\")\n",
    "    with open(cfg_path, \"r\") as f:\n",
    "        cfg_dict = yaml.safe_load(f) or {}\n",
    "    \n",
    "    data_cfg = cfg_dict.get(\"data\", {})\n",
    "    model_cfg = cfg_dict.get(\"model\", {})\n",
    "    \n",
    "    # Sync with neurvps.config\n",
    "    if cfg_M is not None:\n",
    "        for k, v in model_cfg.items():\n",
    "            if isinstance(v, (int, float, bool, str, list, tuple)):\n",
    "                try:\n",
    "                    setattr(cfg_M, k, v)\n",
    "                except Exception:\n",
    "                    pass\n",
    "    \n",
    "    # Set defaults\n",
    "    defaults = {\n",
    "        \"fc_channel\": 1024,\n",
    "        \"multires\": [0.01, 0.05, 0.2, 0.8],\n",
    "        \"smp_pos\": 1,\n",
    "        \"smp_neg\": 1,\n",
    "        \"smp_rnd\": 8,\n",
    "        \"smp_multiplier\": 2.0,\n",
    "        \"output_stride\": 32,\n",
    "        \"upsample_scale\": 4,\n",
    "    }\n",
    "    \n",
    "    if cfg_M is not None:\n",
    "        for k, v in defaults.items():\n",
    "            if not hasattr(cfg_M, k):\n",
    "                setattr(cfg_M, k, v)\n",
    "        output_stride = getattr(cfg_M, \"output_stride\", 32)\n",
    "        upsample_scale = getattr(cfg_M, \"upsample_scale\", 4)\n",
    "    else:\n",
    "        output_stride = defaults[\"output_stride\"]\n",
    "        upsample_scale = defaults[\"upsample_scale\"]\n",
    "    \n",
    "    print(f\"[model] output_stride={output_stride}, upsample_scale={upsample_scale}\")\n",
    "    \n",
    "    # Create backbone\n",
    "    bb = _make_torchvision_backbone(which=\"resnet50\", pretrained=False, out_layer=\"layer3\")\n",
    "    if bb is None:\n",
    "        print(\"[model] torchvision unavailable; using TinyBackbone\")\n",
    "        bb = TinyBackbone()\n",
    "    else:\n",
    "        print(\"[model] using ResNet50 backbone\")\n",
    "    \n",
    "    # Create model\n",
    "    print(f\"[model] creating VanishingNet...\")\n",
    "    model = VanishingNet(bb, output_stride, upsample_scale).to(device).eval()\n",
    "    print(f\"[model] VanishingNet created successfully\")\n",
    "    \n",
    "    # Load checkpoint\n",
    "    print(f\"[model] loading checkpoint from {ckpt_path}\")\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {ckpt_path}\")\n",
    "    \n",
    "    raw = torch.load(ckpt_path, map_location=device)\n",
    "    print(f\"[model] checkpoint loaded | type={type(raw).__name__}\")\n",
    "    \n",
    "    # Extract state_dict\n",
    "    if isinstance(raw, dict):\n",
    "        for key in (\"state_dict\", \"model_state_dict\", \"model\"):\n",
    "            if key in raw and isinstance(raw[key], dict):\n",
    "                state = raw[key]\n",
    "                print(f\"[model] extracted state_dict from key '{key}'\")\n",
    "                break\n",
    "        else:\n",
    "            state = raw\n",
    "            print(f\"[model] using checkpoint dict directly as state\")\n",
    "    else:\n",
    "        state = raw\n",
    "    \n",
    "    print(f\"[model] state_dict has {len(state)} keys\")\n",
    "    \n",
    "    # Remap state keys\n",
    "    mk = list(model.state_dict().keys())\n",
    "    remapped = {}\n",
    "    for k, v in state.items():\n",
    "        kk = k\n",
    "        for pref in (\"module.\", \"model.\"):\n",
    "            if kk.startswith(pref):\n",
    "                kk = kk[len(pref):]\n",
    "                break\n",
    "        \n",
    "        has_anet = any(kk.startswith(\"anet.\") for kk in mk)\n",
    "        has_backbone = any(kk.startswith(\"backbone.\") for kk in mk)\n",
    "        has_anet_bb = any(kk.startswith(\"anet.backbone.\") for kk in mk)\n",
    "        \n",
    "        if has_backbone and not has_anet_bb and kk.startswith(\"anet.backbone.\"):\n",
    "            kk = kk[len(\"anet.\"):]\n",
    "        if has_anet and not kk.startswith(\"anet.\"):\n",
    "            if kk.startswith(\"backbone.\") or any(kk.startswith(p) for p in (\"fc\", \"bn\", \"conv\", \"score\")):\n",
    "                kk = \"anet.\" + kk\n",
    "        if not has_anet and kk.startswith(\"anet.\"):\n",
    "            kk = kk[len(\"anet.\"):]\n",
    "        \n",
    "        remapped[kk] = v\n",
    "    \n",
    "    pruned = {k: v for k, v in remapped.items() if k in mk}\n",
    "    inc = model.load_state_dict(pruned, strict=False)\n",
    "    \n",
    "    missing = len(getattr(inc, \"missing_keys\", []))\n",
    "    unexpected = len(getattr(inc, \"unexpected_keys\", []))\n",
    "    print(f\"[model] loaded | missing={missing} unexpected={unexpected}\")\n",
    "    \n",
    "    focal = float(data_cfg.get(\"focal\", 1.0))\n",
    "    return model, focal\n",
    "\n",
    "# Load model\n",
    "model, focal = load_model_robust(str(CFG_GSV), str(CKPT), DEVICE)\n",
    "print(f\"✓ Model ready | focal={focal:.2f}px | device={DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f168ae4f-3053-452a-b6cc-4951792ac9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. INFERENCE UTILITIES\n",
    "def fib_sphere(n: int) -> np.ndarray:\n",
    "    ga = (1.0 + 5.0**0.5) / 2.0\n",
    "    frac = 2.0 - ga\n",
    "    z = np.linspace(1 - 1.0/n, -1 + 1.0/n, n)\n",
    "    theta = 2*np.pi * ((np.arange(n)*frac) % 1.0)\n",
    "    r = np.sqrt(np.maximum(0.0, 1 - z*z))\n",
    "    x = r*np.cos(theta)\n",
    "    y = r*np.sin(theta)\n",
    "    v = np.stack([x, y, z], axis=1).astype(np.float32)\n",
    "    v /= np.linalg.norm(v, axis=1, keepdims=True)\n",
    "    return v\n",
    "\n",
    "def to_pixel_local(v: np.ndarray, focal: float, width: int, height: int) -> np.ndarray:\n",
    "    vx, vy, vz = float(v[0]), float(v[1]), float(v[2])\n",
    "    W, H = float(width), float(height)\n",
    "    cx, cy = W/2.0, H/2.0\n",
    "    eps = 1e-6\n",
    "    if -eps < vz < eps:\n",
    "        vz = eps if vz >= 0 else -eps\n",
    "    x = focal * vx / vz + cx\n",
    "    y = focal * vy / vz + cy\n",
    "    return np.array([x, y], dtype=np.float32)\n",
    "\n",
    "def infer_one(\n",
    "    model, focal, device, img_path,\n",
    "    k_top=3, n_candidates=1024,   # n_candidates is ignored now; keep for signature compatibility\n",
    "    imagenet_norm=True, verbose=False\n",
    "):\n",
    "    try:\n",
    "        from neurvps.config import C as cfg_C  # read num_vpts seen by NeurVPS\n",
    "\n",
    "        img = io.imread(img_path)\n",
    "        if img.ndim == 2:\n",
    "            img = np.stack([img]*3, axis=-1)\n",
    "\n",
    "        H, W = img.shape[:2]\n",
    "\n",
    "        # to tensor [1,3,H,W]\n",
    "        x = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0\n",
    "        if imagenet_norm:\n",
    "            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "            std  = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "            x = (x - mean) / std\n",
    "        x = x.unsqueeze(0).to(device)\n",
    "\n",
    "        # ---- CRITICAL: pass exactly C.io.num_vpts seed directions ----\n",
    "        num_v = getattr(getattr(cfg_C, \"io\", None), \"num_vpts\", 3)\n",
    "\n",
    "        if num_v == 3:\n",
    "            # Use orthogonal unit axes as seeds (network will refine internally)\n",
    "            vpts = torch.tensor(\n",
    "                [[1.0, 0.0, 0.0],\n",
    "                 [0.0, 1.0, 0.0],\n",
    "                 [0.0, 0.0, 1.0]],\n",
    "                dtype=torch.float32, device=device\n",
    "            )\n",
    "        else:\n",
    "            # Evenly spread seeds if different count is configured\n",
    "            vpts_np = fib_sphere(num_v)                # (num_v, 3)\n",
    "            vpts = torch.from_numpy(vpts_np).to(device)\n",
    "        # --------------------------------------------------------------\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"  input shape: {x.shape}, seeds: {tuple(vpts.shape)} on {vpts.device}\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # NeurVPS expects both the image and the seed VPs\n",
    "            out = model({\"image\": x, \"vpts\": vpts})\n",
    "\n",
    "        # Handle output (many forks expose 'scores' or 'output')\n",
    "        if isinstance(out, dict):\n",
    "            scores = out.get(\"scores\", out.get(\"output\", None))\n",
    "        else:\n",
    "            scores = out\n",
    "        if scores is None:\n",
    "            raise RuntimeError(\"Model returned None for scores\")\n",
    "\n",
    "        if not torch.is_tensor(scores):\n",
    "            scores = torch.as_tensor(scores)\n",
    "        scores = scores.detach().cpu().float()\n",
    "\n",
    "        # If model returns scores per multires level [N, L], average over levels\n",
    "        s = scores.mean(dim=1) if scores.ndim == 2 else scores\n",
    "\n",
    "        if verbose:\n",
    "            smin = float(s.min()) if s.numel() else float(\"nan\")\n",
    "            smax = float(s.max()) if s.numel() else float(\"nan\")\n",
    "            print(f\"  scores: shape={tuple(s.shape)} range=({smin:.4f}, {smax:.4f})\")\n",
    "\n",
    "        # Top-k over candidates internally sampled by the model (indices map to seeds’ refinements)\n",
    "        k = min(k_top, s.numel())\n",
    "        top_idx = torch.topk(s, k=k).indices.numpy()\n",
    "\n",
    "        # We don’t have direct 3D directions back here; project seed directions as coarse VP pixels\n",
    "        # (If your fork returns refined 3D VPs, adapt here to use them.)\n",
    "        # For now, project the seeds themselves—good enough to verify pipeline is running.\n",
    "        # If you prefer, you can map 'top_idx' modulo 'num_v' to pick a seed per best score.\n",
    "        result = {}\n",
    "        for i in range(k):\n",
    "            seed_j = int(top_idx[i] % max(1, num_v))\n",
    "            v3 = vpts[seed_j].detach().cpu().numpy()\n",
    "            px = to_pixel_local(v3, focal=focal, width=W, height=H)\n",
    "            result[f\"vp{i+1}\"] = {\"x\": float(px[0]), \"y\": float(px[1]), \"score\": float(s[int(top_idx[i])])}\n",
    "\n",
    "        return result, True\n",
    "\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            import traceback\n",
    "            print(f\"  [error] {e}\")\n",
    "            traceback.print_exc()\n",
    "        return {\"error\": str(e)}, False\n",
    "\n",
    "def run_inference_pipeline(model, focal, device, input_dir, output_dir,\n",
    "                           k_top=3, n_candidates=1024):\n",
    "    input_path = Path(input_dir)\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    image_files = []\n",
    "    for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.JPG\", \"*.PNG\"):\n",
    "        image_files.extend(input_path.glob(ext))\n",
    "    \n",
    "    print(f\"\\n[inference] Found {len(image_files)} images in {input_dir}\")\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        print(\"[inference] No images found!\")\n",
    "        return {}\n",
    "    \n",
    "    results = {}\n",
    "    success_count = 0\n",
    "    \n",
    "    for idx, img_path in enumerate(tqdm(image_files, desc=\"Processing\")):\n",
    "        verbose = (idx == 0)\n",
    "        \n",
    "        result, success = infer_one(\n",
    "            model, focal, device, str(img_path),\n",
    "            k_top=k_top, n_candidates=n_candidates,\n",
    "            imagenet_norm=True, verbose=verbose\n",
    "        )\n",
    "        \n",
    "        if success:\n",
    "            success_count += 1\n",
    "        \n",
    "        out_file = output_path / f\"{img_path.stem}.json\"\n",
    "        with open(out_file, \"w\") as f:\n",
    "            json.dump(result, f, indent=2)\n",
    "        \n",
    "        results[img_path.name] = result\n",
    "    \n",
    "    print(f\"\\n[done] {success_count}/{len(image_files)} successful\")\n",
    "    print(f\"[done] Results saved to: {output_dir}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52469213-a6c3-4186-9320-650dc54bde06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "NeurVPS Vanishing Point Detection\n",
      "======================================================================\n",
      "Input:  /users/project1/pt01183/Building-height-width/external/neurvps/data/my5_sq\n",
      "Output: /users/project1/pt01183/Building-height-width/external/neurvps/logs/tmm17/my5_vpts\n",
      "Device: cuda:0\n",
      "Focal:  268.51px\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[inference] Found 5 images in /users/project1/pt01183/Building-height-width/external/neurvps/data/my5_sq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|                                         | 0/5 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_269767/1537417751.py\", line 69, in infer_one\n",
      "    out = model({\"image\": x, \"vpts\": vpts})\n",
      "  File \"/mnt/host_scratch/envs/new_geospatial_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/mnt/host_scratch/envs/new_geospatial_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/users/project1/pt01183/Building-height-width/external/neurvps/neurvps/models/vanishing_net.py\", line 53, in forward\n",
      "    add_sample(sample_sphere(vgt, st, ed))\n",
      "  File \"/tmp/ipykernel_269767/2981991302.py\", line 75, in _safe_sample_sphere\n",
      "    v = _np.asarray(v, dtype=_np.float32).reshape(3)  # ensure shape (3,)\n",
      "ValueError: cannot reshape array of size 1 into shape (3,)\n",
      "Processing: 100%|█████████████████████████████████| 5/5 [00:00<00:00, 71.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  input shape: torch.Size([1, 3, 640, 640]), seeds: (3, 3) on cuda:0\n",
      "  [error] cannot reshape array of size 1 into shape (3,)\n",
      "\n",
      "[done] 0/5 successful\n",
      "[done] Results saved to: /users/project1/pt01183/Building-height-width/external/neurvps/logs/tmm17/my5_vpts\n",
      "\n",
      "======================================================================\n",
      "Inference Summary\n",
      "======================================================================\n",
      "✗ 8_139.jpg: cannot reshape array of size 1 into shape (3,)\n",
      "✗ 6_196.jpg: cannot reshape array of size 1 into shape (3,)\n",
      "✗ 2_190.jpg: cannot reshape array of size 1 into shape (3,)\n",
      "✗ 9_196.jpg: cannot reshape array of size 1 into shape (3,)\n",
      "✗ 7_4.jpg: cannot reshape array of size 1 into shape (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. RUN INFERENCE\n",
    "if __name__ == \"__main__\":\n",
    "    IN_DIR = NEURVPS_ROOT / \"data\" / \"my5_sq\"\n",
    "    OUT_DIR = NEURVPS_ROOT / \"logs\" / \"tmm17\" / \"my5_vpts\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"NeurVPS Vanishing Point Detection\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Input:  {IN_DIR}\")\n",
    "    print(f\"Output: {OUT_DIR}\")\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Focal:  {focal:.2f}px\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    results = run_inference_pipeline(\n",
    "        model, focal, DEVICE,\n",
    "        str(IN_DIR), str(OUT_DIR),\n",
    "        k_top=3, n_candidates=1024\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Inference Summary\")\n",
    "    print(\"=\"*70)\n",
    "    for fname, result in results.items():\n",
    "        if \"error\" in result:\n",
    "            print(f\"✗ {fname}: {result['error']}\")\n",
    "        else:\n",
    "            vpts = [f\"{k}: ({v['x']:.1f}, {v['y']:.1f})\" for k, v in result.items()]\n",
    "            print(f\"✓ {fname}\")\n",
    "            for vpt in vpts:\n",
    "                print(f\"    {vpt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260bc77-a63b-498a-8b19-029262c78073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
